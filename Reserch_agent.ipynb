{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7kA5KnHmYSlg",
        "outputId": "ae4882eb-aea6-4434-c9fc-7db54f770ecc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.2\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (0.3.75)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.6.7-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (13.9.4)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.11.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (4.15.0)\n",
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-2.1.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting tavily-python\n",
            "  Downloading tavily_python-0.7.12-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.8-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.5.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich) (2.19.2)\n",
            "Collecting google-ai-generativelanguage<1,>=0.7 (from langchain_google_genai)\n",
            "  Downloading google_ai_generativelanguage-0.7.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting filetype<2,>=1.2 (from langchain_google_genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (5.29.5)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (0.6.1)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tavily-python) (0.11.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.5.1->tavily-python) (2024.11.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.6.7-py3-none-any.whl (153 kB)\n",
            "Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.8-py3-none-any.whl (56 kB)\n",
            "Downloading langchain_google_genai-2.1.12-py3-none-any.whl (50 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.7.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tavily_python-0.7.12-py3-none-any.whl (15 kB)\n",
            "Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "Installing collected packages: filetype, ormsgpack, tavily-python, langgraph-sdk, langgraph-checkpoint, google-ai-generativelanguage, langgraph-prebuilt, langchain_google_genai, langgraph\n",
            "\u001b[2K  Attempting uninstall: google-ai-generativelanguage\n",
            "\u001b[2K    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "\u001b[2K    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "\u001b[2K      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9/9\u001b[0m [langgraph]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.7.0 langchain_google_genai-2.1.12 langgraph-0.6.7 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.8 ormsgpack-1.10.0 tavily-python-0.7.12\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "130a6922ff814e63a5100133f4e3c5e8",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install langchain langchain-core langgraph rich python-dotenv pydantic typing-extensions langchain_google_genai langgraph tavily-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JA0G7ciwY6dq"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "from datetime import datetime\n",
        "from typing import List, Literal, Dict\n",
        "\n",
        "from IPython.display import display, Markdown\n",
        "from rich.console import Console\n",
        "from rich.panel import Panel\n",
        "\n",
        "console = Console()\n",
        "\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"Your_API_KEY\"\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"Your_API_Key\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "SqYF3Wh4Zm1r",
        "outputId": "3eec279d-0378-49d3-f9e6-50b617daf312"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Unexpected argument 'rate_limiters' provided to ChatGoogleGenerativeAI. Did you mean: 'rate_limiter'?\n",
            "/usr/local/lib/python3.12/dist-packages/langchain/chat_models/base.py:324: UserWarning: WARNING! rate_limiters is not default parameter.\n",
            "                rate_limiters was transferred to model_kwargs.\n",
            "                Please confirm that rate_limiters is what you intended.\n",
            "  return _init_chat_model_helper(\n",
            "WARNING:langchain_google_genai.chat_models:Unexpected argument 'rate_limiters' provided to ChatGoogleGenerativeAI. Did you mean: 'rate_limiter'?\n",
            "/usr/local/lib/python3.12/dist-packages/langchain/chat_models/base.py:324: UserWarning: WARNING! rate_limiters is not default parameter.\n",
            "                rate_limiters was transferred to model_kwargs.\n",
            "                Please confirm that rate_limiters is what you intended.\n",
            "  return _init_chat_model_helper(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────────────────── Models ─────────────────────────────────────────────────────╮\n",
              "│  Gemini models initialized (gemini-1.5-flash).                                                                  │\n",
              "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
              "</pre>\n"
            ],
            "text/plain": [
              "╭──────────────────────────────────────────────────── Models ─────────────────────────────────────────────────────╮\n",
              "│  Gemini models initialized (gemini-1.5-flash).                                                                  │\n",
              "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────────────────── Tavily ─────────────────────────────────────────────────────╮\n",
              "│ Tavily client initialized                                                                                       │\n",
              "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
              "</pre>\n"
            ],
            "text/plain": [
              "╭──────────────────────────────────────────────────── Tavily ─────────────────────────────────────────────────────╮\n",
              "│ Tavily client initialized                                                                                       │\n",
              "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Models and Tavily client initialization\n",
        "from langchain.chat_models import init_chat_model\n",
        "from tavily import TavilyClient\n",
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "\n",
        "def invoke_with_retries(model_obj, messages, max_attempts=4, initial_delay=2):\n",
        "    attempt = 0\n",
        "    delay = initial_delay\n",
        "    last_exc = None\n",
        "    while attempt < max_attempts:\n",
        "        try:\n",
        "            resp = model_obj.invoke(messages)\n",
        "            return resp\n",
        "        except Exception as e:\n",
        "            last_exc = e\n",
        "            attempt += 1\n",
        "            console.print(f\"[yellow]Model call failed (attempt {attempt}/{max_attempts}): {type(e).__name__}: {e}[/yellow]\")\n",
        "\n",
        "            time.sleep(delay)\n",
        "            delay *= 2\n",
        "    raise last_exc\n",
        "\n",
        "\n",
        "try:\n",
        "    summarization_model = init_chat_model(\"gemini-1.5-flash\", model_provider=\"google_genai\", temperature=0, rate_limiters=None)\n",
        "    compress_model = init_chat_model(\"gemini-1.5-flash\", model_provider=\"google_genai\", temperature=0, rate_limiters=None)\n",
        "    console.print(Panel(\" Gemini models initialized .\", title=\"Models\"))\n",
        "except Exception as e:\n",
        "    console.print(Panel(f\"[red]Could not init Gemini models: {e}[/red]\\nYou may need to install/enable the provider or check your API key.\", title=\"Model Init Error\"))\n",
        "\n",
        "# Tavily client\n",
        "try:\n",
        "    tavily_client = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])\n",
        "    console.print(Panel(\"Tavily client initialized\", title=\"Tavily\"))\n",
        "except Exception as e:\n",
        "    console.print(Panel(f\"[red]Tavily init error: {e}[/red]\", title=\"Tavily Error\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tAv-s3f3a2oS"
      },
      "outputs": [],
      "source": [
        "from urllib.parse import urlparse\n",
        "\n",
        "def get_today_str() -> str:\n",
        "    return datetime.now().strftime(\"%a %b %d, %Y\")\n",
        "\n",
        "def make_verbatim_excerpt(raw: str, max_chars: int = 400) -> str:\n",
        "    if not raw:\n",
        "        return \"\"\n",
        "    paragraphs = [p.strip() for p in raw.split(\"\\n\\n\") if p.strip()]\n",
        "    if paragraphs:\n",
        "        excerpt = paragraphs[0]\n",
        "        return excerpt[:max_chars] + (\"...\" if len(excerpt) > max_chars else \"\")\n",
        "    else:\n",
        "        return raw[:max_chars] + (\"...\" if len(raw) > max_chars else \"\")\n",
        "\n",
        "def deduplicate_search_results(search_results: List[dict]) -> dict:\n",
        "    unique_results = {}\n",
        "    citation_map = {}\n",
        "    citation_list = []\n",
        "    next_citation = 1\n",
        "    retrieved_at = datetime.now().isoformat()\n",
        "    for response in search_results:\n",
        "        for result in response.get('results', []):\n",
        "            url = result.get('url')\n",
        "            if not url:\n",
        "                continue\n",
        "            if url not in unique_results:\n",
        "                metadata = {\n",
        "                    \"title\": result.get(\"title\") or urlparse(url).netloc,\n",
        "                    \"url\": url,\n",
        "                    \"published\": result.get(\"published\") or result.get(\"date\") or None,\n",
        "                    \"author\": result.get(\"author\") or None,\n",
        "                    \"retrieved_at\": retrieved_at,\n",
        "                    \"fetch_method\": \"tavily_search\",\n",
        "                    \"raw_content\": result.get(\"raw_content\") or result.get(\"content\") or \"\"\n",
        "                }\n",
        "                unique_results[url] = metadata\n",
        "                citation_map[url] = next_citation\n",
        "                citation_list.append((next_citation, url, metadata[\"title\"], metadata))\n",
        "                next_citation += 1\n",
        "    return {\n",
        "        \"unique_results\": unique_results,\n",
        "        \"citation_map\": citation_map,\n",
        "        \"citation_list\": citation_list\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3bpEAsjxa8IR"
      },
      "outputs": [],
      "source": [
        "def tavily_search_multiple(search_queries: List[str], max_results: int = 3, topic: Literal[\"general\",\"news\",\"finance\"]=\"general\", include_raw_content: bool = True) -> List[dict]:\n",
        "    \"\"\"\n",
        "    Execute a list of queries using Tavily (sequentially).\n",
        "    Keep the number of queries small to avoid token explosion.\n",
        "    \"\"\"\n",
        "    search_docs = []\n",
        "    for query in search_queries:\n",
        "        console.print(Panel(f\"  {query}\", title=\"Tavily Search\"))\n",
        "        # Wrap in try/except to avoid full crash on a single failure\n",
        "        try:\n",
        "            result = tavily_client.search(query, max_results=max_results, include_raw_content=include_raw_content, topic=topic)\n",
        "            search_docs.append(result)\n",
        "            # brief pause to avoid hitting rate limits\n",
        "            time.sleep(1.0)\n",
        "        except Exception as e:\n",
        "            console.print(f\"[red]Tavily search failed for query '{query}': {e}[/red]\")\n",
        "            # append an empty structure so downstream code can proceed\n",
        "            search_docs.append({\"results\": []})\n",
        "    return search_docs\n",
        "\n",
        "# Process search results into cleaned summaries using summarization_model\n",
        "def summarize_webpage_content(webpage_content: str) -> str:\n",
        "    \"\"\"\n",
        "    Summarize raw webpage content using summarization_model.\n",
        "    Keep the prompt concise to reduce token usage.\n",
        "    \"\"\"\n",
        "    if not webpage_content:\n",
        "        return \"\"\n",
        "    prompt = f\"Summarize the important factual points from the webpage content below in 3-6 concise sentences. Preserve dates/names/numbers.\\n\\nContent:\\n{webpage_content[:4000]}\"\n",
        "    try:\n",
        "        # Use System + Human style messages (langchain model.invoke expects message objects)\n",
        "        resp = invoke_with_retries(summarization_model, [HumanMessage(content=prompt)], max_attempts=3, initial_delay=2)\n",
        "        # Response may be an object with .summary or .content depending on provider - handle both\n",
        "        if hasattr(resp, \"summary\"):\n",
        "            return resp.summary\n",
        "        elif hasattr(resp, \"content\"):\n",
        "            return str(resp.content)\n",
        "        else:\n",
        "            return str(resp)\n",
        "    except Exception as e:\n",
        "        console.print(f\"[red]Summarization failed: {e}[/red]\")\n",
        "        return (webpage_content[:800] + \"...\") if len(webpage_content) > 800 else webpage_content\n",
        "\n",
        "def process_search_results(deduped: dict) -> dict:\n",
        "    \"\"\"\n",
        "    For each unique URL, produce a cleaned summary and verbatim excerpt.\n",
        "    \"\"\"\n",
        "    unique_results = deduped[\"unique_results\"]\n",
        "    citation_map = deduped[\"citation_map\"]\n",
        "    processed = {}\n",
        "    for url, meta in unique_results.items():\n",
        "        raw = meta.get(\"raw_content\", \"\")\n",
        "        verbatim_excerpt = make_verbatim_excerpt(raw)\n",
        "        # Summarize raw content (may be long) - summarizer will truncate input to first ~4k chars\n",
        "        cleaned_summary = summarize_webpage_content(raw) if raw else meta.get(\"title\", \"\")\n",
        "        processed[url] = {\n",
        "            \"title\": meta[\"title\"],\n",
        "            \"url\": url,\n",
        "            \"published\": meta.get(\"published\"),\n",
        "            \"author\": meta.get(\"author\"),\n",
        "            \"retrieved_at\": meta.get(\"retrieved_at\"),\n",
        "            \"fetch_method\": meta.get(\"fetch_method\"),\n",
        "            \"verbatim_excerpt\": verbatim_excerpt,\n",
        "            \"cleaned_summary\": cleaned_summary,\n",
        "            \"raw_content\": raw\n",
        "        }\n",
        "    return {\"processed\": processed, \"citation_map\": citation_map, \"citation_list\": deduped[\"citation_list\"]}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Tkdw9I-ZbDN7"
      },
      "outputs": [],
      "source": [
        "def build_joined_notes_for_report(processed_container: dict) -> str:\n",
        "    \"\"\"\n",
        "    Build a human-readable joined notes string (title + url + cleaned_summary + verbatim excerpt)\n",
        "    to feed into the final compressor model.\n",
        "    \"\"\"\n",
        "    processed = processed_container[\"processed\"]\n",
        "    citation_list = processed_container[\"citation_list\"]\n",
        "    lines = []\n",
        "    lines.append(\"SOURCES:\\n\")\n",
        "    for (num, url, title, meta) in citation_list:\n",
        "        lines.append(f\"[{num}] {title} — {url} (retrieved: {meta.get('retrieved_at')})\")\n",
        "    lines.append(\"\\n---\\n\\nRESULTS:\\n\")\n",
        "    for url, item in processed.items():\n",
        "        lines.append(f\"Title: {item['title']}\")\n",
        "        lines.append(f\"URL: {item['url']}\")\n",
        "        lines.append(f\"Published: {item.get('published')}\")\n",
        "        lines.append(f\"Author: {item.get('author')}\")\n",
        "        lines.append(\"CLEAN SUMMARY:\")\n",
        "        lines.append(item[\"cleaned_summary\"] or \"\")\n",
        "        lines.append(\"\\nVERBATIM EXCERPT:\")\n",
        "        lines.append(item[\"verbatim_excerpt\"] or \"\")\n",
        "        lines.append(\"\\n\" + (\"-\"*80) + \"\\n\")\n",
        "    return \"\\n\".join(lines)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3uM1CSW9bEru"
      },
      "outputs": [],
      "source": [
        "def generate_structured_report(topic: str, search_max_results=3, queries_extra: List[str]=None):\n",
        "    \"\"\"\n",
        "    Main pipeline:\n",
        "     1) Search a few variations of the topic using Tavily\n",
        "     2) Deduplicate & summarize results\n",
        "     3) Send cleaned notes to Gemini to produce the structured Markdown report\n",
        "    \"\"\"\n",
        "\n",
        "    base_queries = [topic]\n",
        "    if queries_extra:\n",
        "        base_queries += queries_extra\n",
        "    else:\n",
        "        base_queries += [f\"{topic} review\", f\"{topic} statistics\", f\"{topic} research\"]\n",
        "    base_queries = base_queries[:4]\n",
        "\n",
        "    raw_search_results = tavily_search_multiple(base_queries, max_results=search_max_results, topic=\"general\", include_raw_content=True)\n",
        "    deduped = deduplicate_search_results(raw_search_results)\n",
        "    processed_container = process_search_results(deduped)\n",
        "\n",
        "    joined_notes = build_joined_notes_for_report(processed_container)\n",
        "\n",
        "    structured_prompt = f\"\"\"\n",
        "You are an expert research analyst. Using ONLY the notes given below (do not invent sources), create a full Markdown research report on the topic: \"{topic}\".\n",
        "\n",
        "The output MUST be Markdown and include these sections (in this order):\n",
        "1. Title (a concise clear title)\n",
        "2. Executive Summary (3-5 sentences)\n",
        "3. Key Facts / Statistics (bullet list)\n",
        "4. Detailed Explanation (at least 3 paragraphs)\n",
        "5. Comparison Table (a markdown table comparing at least two alternatives/important items relevant to the topic)\n",
        "6. Pros & Cons (bullet lists per item)\n",
        "7. Conclusion (2-4 sentences)\n",
        "8. References (one clickable URL per line; each inline citation must appear in this References section)\n",
        "\n",
        "Below are the notes you MUST use as sources. Use inline citations like [Name - URL] in the Findings and Table, and ensure all those citations are listed in References. Do not invent sources.\n",
        "\n",
        "NOTES:\n",
        "{joined_notes}\n",
        "\n",
        "Produce the full Markdown report now.\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        console.print(Panel(\" Requesting Gemini to produce final structured report (primary model\", title=\"Report Generation\"))\n",
        "        resp = invoke_with_retries(compress_model, [SystemMessage(content=f\"Date: {get_today_str()}\"), HumanMessage(content=structured_prompt)], max_attempts=4, initial_delay=3)\n",
        "        final_text = getattr(resp, \"content\", None) or str(resp)\n",
        "        with open(\"research_report.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(final_text)\n",
        "        console.print(Panel(\" Report generated and saved to research_report.md\", title=\"Done\"))\n",
        "        display(Markdown(final_text))\n",
        "        return {\"report\": final_text, \"processed\": processed_container}\n",
        "    except Exception as e_main:\n",
        "        console.print(Panel(f\"[red]Primary Gemini model failed: {e_main}[/red]\\nAttempting fallback to gemini-1.5-flash...\", title=\"Fallback\"))\n",
        "        try:\n",
        "            fallback_model = init_chat_model(\"gemini-1.5-flash\", model_provider=\"google_genai\", temperature=0, rate_limiters=None)\n",
        "            resp2 = invoke_with_retries(fallback_model, [SystemMessage(content=f\"Date: {get_today_str()}\"), HumanMessage(content=structured_prompt)], max_attempts=3, initial_delay=3)\n",
        "            final_text = getattr(resp2, \"content\", None) or str(resp2)\n",
        "            with open(\"research_report.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(final_text)\n",
        "            console.print(Panel(\" Report generated with fallback model and saved to research_report.md\", title=\"Done (fallback)\"))\n",
        "            display(Markdown(final_text))\n",
        "            return {\"report\": final_text, \"processed\": processed_container}\n",
        "        except Exception as e_fb:\n",
        "            console.print(Panel(f\"[red]Fallback also failed: {e_fb}[/red]\\nYou may have exhausted your Gemini quota or be experiencing network/timeouts.\", title=\"Final Failure\"))\n",
        "            raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bvFA8gf3bgFZ",
        "outputId": "bb8baacc-c24c-420c-93d4-fb1048673293"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your research topic (e.g., 'Best coffee shops in San Francisco based on coffee quality'): Best cake in bangalore\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭───────────────────────────────────────────────── Tavily Search ─────────────────────────────────────────────────╮\n",
              "│   Best cake in bangalore                                                                                        │\n",
              "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
              "</pre>\n"
            ],
            "text/plain": [
              "╭───────────────────────────────────────────────── Tavily Search ─────────────────────────────────────────────────╮\n",
              "│   Best cake in bangalore                                                                                        │\n",
              "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭───────────────────────────────────────────────── Tavily Search ─────────────────────────────────────────────────╮\n",
              "│   Best cake in bangalore review                                                                                 │\n",
              "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
              "</pre>\n"
            ],
            "text/plain": [
              "╭───────────────────────────────────────────────── Tavily Search ─────────────────────────────────────────────────╮\n",
              "│   Best cake in bangalore review                                                                                 │\n",
              "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭───────────────────────────────────────────────── Tavily Search ─────────────────────────────────────────────────╮\n",
              "│   Best cake in bangalore statistics                                                                             │\n",
              "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
              "</pre>\n"
            ],
            "text/plain": [
              "╭───────────────────────────────────────────────── Tavily Search ─────────────────────────────────────────────────╮\n",
              "│   Best cake in bangalore statistics                                                                             │\n",
              "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭───────────────────────────────────────────────── Tavily Search ─────────────────────────────────────────────────╮\n",
              "│   Best cake in bangalore research                                                                               │\n",
              "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
              "</pre>\n"
            ],
            "text/plain": [
              "╭───────────────────────────────────────────────── Tavily Search ─────────────────────────────────────────────────╮\n",
              "│   Best cake in bangalore research                                                                               │\n",
              "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────── Report Generation ───────────────────────────────────────────────╮\n",
              "│  Requesting Gemini to produce final structured report (primary model: gemini-1.5-pro)                           │\n",
              "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
              "</pre>\n"
            ],
            "text/plain": [
              "╭─────────────────────────────────────────────── Report Generation ───────────────────────────────────────────────╮\n",
              "│  Requesting Gemini to produce final structured report (primary model: gemini-1.5-pro)                           │\n",
              "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭───────────────────────────────────────────────────── Done ──────────────────────────────────────────────────────╮\n",
              "│  Report generated and saved to research_report.md                                                               │\n",
              "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
              "</pre>\n"
            ],
            "text/plain": [
              "╭───────────────────────────────────────────────────── Done ──────────────────────────────────────────────────────╮\n",
              "│  Report generated and saved to research_report.md                                                               │\n",
              "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "# Best Cakes in Bangalore: A Comparative Analysis\n",
              "\n",
              "## Executive Summary\n",
              "\n",
              "Bangalore, crowned \"Cake Capital\" in 2023 by Swiggy with 8.5 million cake orders [6 - https://www.ndtv.com/bangalore-news/bengaluru-cake-capital-2023-8-5-million-orders-swiggy-blog-post-4679508], boasts a diverse range of bakeries.  This report analyzes several highly-rated options, considering customer reviews, product variety, and overall reputation.  While numerous bakeries excel,  determining a single \"best\" is subjective and depends on individual preferences.  This report aims to provide a comprehensive overview to aid consumers in making informed decisions.\n",
              "\n",
              "\n",
              "## Key Facts / Statistics\n",
              "\n",
              "* Bangalore received the title of \"Cake Capital\" in 2023, based on 8.5 million cake orders via Swiggy [6 - https://www.ndtv.com/bangalore-news/bengaluru-cake-capital-2023-8-5-million-orders-swiggy-blog-post-4679508].\n",
              "* Chebel Patisserie offers a wide selection of cakes, with prices ranging up to Rs. 2,980.00 and same-day delivery [1 - https://chebelpatisserie.com/collections/best-cakes-in-bangalore?srsltid=AfmBOoqGjRIx9ztV-MAixJIzy6IQUc8xdhAUsss2qUahgVj6wgkPt7Ko].\n",
              "* Patisserie Nitash in Cooke Town is highly praised for its exceptional cakes, requiring a one-day advance order [3 - https://www.reddit.com/r/bangalore/comments/ppi86r/best_cake_place_in_bengaluru/].\n",
              "* Glen's Bakehouse is known for its high-quality cakes and offers delivery within and outside Bangalore [4 - https://ind.5bestincity.com/cake-shops-in-bengaluru-ka].\n",
              "* Several other bakeries, including Vallombrosa, Sweetstuff, Monginis, La Gateau, and Chef Bakers, receive frequent positive mentions [2 - https://www.quora.com/Where-can-I-find-the-best-cakes-in-Bangalore].\n",
              "* Sreenivasa Brahmins Bakery and Carlos The Cake Cafe have significant online ratings (3.9k and 1.7k respectively) [7 - https://www.justdial.com/Bangalore/Cake-Shops/nct-10070075].\n",
              "\n",
              "\n",
              "## Detailed Explanation\n",
              "\n",
              "Bangalore's thriving culinary scene extends to its impressive array of cake shops.  Online platforms like Swiggy highlight the city's immense cake consumption, solidifying its reputation as a \"Cake Capital\" [6 - https://www.ndtv.com/bangalore-news/bengaluru-cake-capital-2023-8-5-million-orders-swiggy-blog-post-4679508].  Numerous online reviews and recommendations point to a variety of bakeries catering to diverse tastes and preferences.  While some, like Chebel Patisserie, offer extensive online menus with customer reviews [1 - https://chebelpatisserie.com/collections/best-cakes-in-bangalore?srsltid=AfmBOoqGjRIx9ztV-MAixJIzy6IQUc8xdhAUsss2qUahgVj6wgkPt7Ko], others, like Patisserie Nitash, garner significant praise for their exceptional quality, albeit with a requirement for advance orders [3 - https://www.reddit.com/r/bangalore/comments/ppi86r/best_cake_place_in_bengaluru/].  The sheer number of options underscores the competitive nature of the Bangalore cake market.\n",
              "\n",
              "The diversity of options extends beyond online platforms.  Quora discussions reveal a range of personal preferences, highlighting bakeries like Vallombrosa, Sweetstuff, and Monginis as popular choices [2 - https://www.quora.com/Where-can-I-find-the-best-cakes-in-Bangalore].  This suggests that the \"best\" cake in Bangalore is highly subjective, depending on individual preferences for flavor profiles, cake types, and price points.  Furthermore, the inclusion of bakeries like Glen's Bakehouse, known for their high-quality products and delivery services, emphasizes the accessibility and convenience offered by many establishments [4 - https://ind.5bestincity.com/cake-shops-in-bengaluru-ka].\n",
              "\n",
              "Ultimately, the search for the \"best\" cake in Bangalore requires considering individual preferences and exploring the diverse options available.  While online reviews and ratings provide valuable insights, personal experience remains crucial in determining one's preferred bakery.  The sheer volume of cake orders and the variety of highly-rated establishments confirm Bangalore's well-deserved reputation as a cake lover's paradise.\n",
              "\n",
              "\n",
              "## Comparison Table\n",
              "\n",
              "| Bakery                     | Speciality                               | Price Range (approx.) | Delivery Options | Customer Reviews (Source) |\n",
              "|-----------------------------|-------------------------------------------|-----------------------|--------------------|---------------------------|\n",
              "| Chebel Patisserie           | Wide variety, mousse, entremets          | Up to Rs. 2,980.00    | Same-day available [1] | 4.5-5.0 stars (various cakes) [1] |\n",
              "| Patisserie Nitash          | Exceptional cakes (requires advance order) | Unknown                | Unknown            | \"Best cake ever\" [3]       |\n",
              "\n",
              "\n",
              "## Pros & Cons\n",
              "\n",
              "**Chebel Patisserie:**\n",
              "\n",
              "**Pros:**\n",
              "* Wide variety of cakes.\n",
              "* High customer ratings.\n",
              "* Same-day delivery available.\n",
              "\n",
              "**Cons:**\n",
              "* Price range may be high for some.\n",
              "* Limited information on specific cake ingredients.\n",
              "\n",
              "\n",
              "**Patisserie Nitash:**\n",
              "\n",
              "**Pros:**\n",
              "* Exceptionally high quality cakes.\n",
              "\n",
              "**Cons:**\n",
              "* Requires one-day advance order.\n",
              "* Limited information available online.\n",
              "\n",
              "\n",
              "## Conclusion\n",
              "\n",
              "Determining the single \"best\" cake in Bangalore is a subjective endeavor.  However, this report highlights several top contenders, each offering unique strengths.  Chebel Patisserie provides a wide selection with convenient delivery, while Patisserie Nitash receives rave reviews for exceptional quality.  Ultimately, the ideal choice depends on individual preferences and priorities.  Further research, including personal visits and taste tests, is recommended for a definitive conclusion.\n",
              "\n",
              "\n",
              "## References\n",
              "\n",
              "[1] Best Cakes in Bangalore | Order Top Selling Cakes at Chebel — https://chebelpatisserie.com/collections/best-cakes-in-bangalore?srsltid=AfmBOoqGjRIx9ztV-MAixJIzy6IQUc8xdhAUsss2qUahgVj6wgkPt7Ko\n",
              "[2] Where can I find the best cakes in Bangalore? - Bengaluru - Quora — https://www.quora.com/Where-can-I-find-the-best-cakes-in-Bangalore\n",
              "[3] best cake place in bengaluru - bangalore - Reddit — https://www.reddit.com/r/bangalore/comments/ppi86r/best_cake_place_in_bengaluru/\n",
              "[4] 5 Best Cake shops in Bangalore, Karnataka - 5BestINcity.com — https://ind.5bestincity.com/cake-shops-in-bengaluru-ka\n",
              "[5] The 50 best cake shops and cake bakeries in Bengaluru - Wanderlog — https://wanderlog.com/list/geoCategory/18657/best-cake-shops-and-cake-bakeries-in-bengaluru\n",
              "[6] Bengaluru Cake Capital 2023 8.5 Million Orders Swiggy ... — https://www.ndtv.com/bangalore-news/bengaluru-cake-capital-2023-8-5-million-orders-swiggy-blog-post-4679508\n",
              "[7] Top Cake Shops in Bangalore - Best Cake Bakeries — https://www.justdial.com/Bangalore/Cake-Shops/nct-10070075\n",
              "[8] Discover Bangalore's Best Bakeries: Top 5 Spots for Cakes, Puffs ... — https://www.instagram.com/reel/DK1wp-yyxwO/"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "topic = input(\"Enter your research topic (e.g., 'Best coffee shops in San Francisco based on coffee quality'): \").strip()\n",
        "if not topic:\n",
        "    topic = \"Best coffee shops in San Francisco based on coffee quality\"\n",
        "\n",
        "result = generate_structured_report(topic, search_max_results=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2LwcUDIefTq",
        "outputId": "8c73b623-4a77-4026-ef8e-89f7c1caa967"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.12/dist-packages (2.1.12)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (0.9.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.75)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.27)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: google-ai-generativelanguage<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: filetype<2,>=1.2 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install langchain langchain-google-genai tabulate\n",
        "\n",
        "# Imports\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from IPython.display import display, Markdown\n",
        "from datetime import datetime\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With Date Display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5G4rFgZJeima"
      },
      "outputs": [],
      "source": [
        "os.environ[\"GOOGLE_API_KEY\"] = \"Your_API_Key\"\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    temperature=0.2,\n",
        "    max_output_tokens=2048,\n",
        "    timeout=120\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "exwc6BJeew2a"
      },
      "outputs": [],
      "source": [
        "today = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "report_prompt = PromptTemplate.from_template(\"\"\"\n",
        "You are a research analyst. Today’s date is **{today}**.\n",
        "Always include the date in the title of the report and again in the Executive Summary.\n",
        "\n",
        "Write a **comprehensive research report** on the topic below.\n",
        "\n",
        "Topic: {topic}\n",
        "\n",
        "Your report **must** include:\n",
        "1. Title including today’s date\n",
        "2. Executive Summary (mention today’s date)\n",
        "3. Key Facts / Statistics (bullet points)\n",
        "4. Detailed Explanation (at least 3 paragraphs)\n",
        "5. Comparison Table of at least 2 alternatives (with columns for Feature, Option A, Option B)\n",
        "6. Pros & Cons (bullet points)\n",
        "7. Citations / References (list of URLs or titles)\n",
        "\n",
        "Use clear Markdown headings for each section.\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S19HXYm8e2C4",
        "outputId": "372d5416-17ca-4e23-9f10-fe3f49dcd864"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2054275436.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  chain = LLMChain(llm=llm, prompt=report_prompt)\n"
          ]
        }
      ],
      "source": [
        "chain = LLMChain(llm=llm, prompt=report_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UQqzbTSre8Ky",
        "outputId": "875d48df-c9ca-4792-88b4-8288539df7c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2423038986.py:3: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  report = chain.run(topic=topic, today=today)\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "# Best Anime with Suspense and Thriller Genre - 2025-09-20\n",
              "\n",
              "## Executive Summary\n",
              "\n",
              "This report, compiled on 2025-09-20, analyzes the best anime series blending suspense and thriller genres.  The report identifies key characteristics of successful anime within this niche, examines several top contenders, and compares two leading examples to highlight their strengths and weaknesses.  The analysis reveals that the success of these anime hinges on intricate plots, compelling characters, and masterful use of atmosphere to build tension and keep viewers engaged.  The report concludes with recommendations for further research into the evolving landscape of suspense and thriller anime.\n",
              "\n",
              "\n",
              "## Key Facts / Statistics\n",
              "\n",
              "* The popularity of anime in the suspense and thriller genres has significantly increased in recent years, driven by streaming services and wider global accessibility.\n",
              "*  Many successful anime in this genre incorporate elements of mystery, psychological horror, and action to enhance the suspense.\n",
              "*  Fan engagement and online discussions (forums, social media) are crucial indicators of an anime's success and lasting impact within the genre.\n",
              "*  The average runtime for successful suspense/thriller anime series is between 12-24 episodes.\n",
              "*  A strong emphasis on character development and complex motivations is vital for maintaining audience interest throughout the narrative.\n",
              "\n",
              "\n",
              "## Detailed Explanation\n",
              "\n",
              "The anime landscape offers a rich tapestry of suspense and thriller narratives, captivating audiences with intricate plots, unpredictable twists, and morally ambiguous characters.  Successful anime in this genre often masterfully blend elements of mystery, psychological horror, and action to create a compelling and immersive experience.  The best examples go beyond simple chase sequences or jump scares, instead focusing on building slow-burning tension through atmospheric visuals, unsettling sound design, and carefully crafted character interactions.  This allows viewers to become deeply invested in the unfolding narrative and actively participate in unraveling the mysteries presented.\n",
              "\n",
              "One key element contributing to the success of suspense/thriller anime is the development of complex and relatable characters.  Viewers need to connect with the protagonists and antagonists on an emotional level, understanding their motivations, even if those motivations are morally questionable.  This emotional investment significantly increases the impact of plot twists and reveals, making the experience more engaging and memorable.  Furthermore, the use of foreshadowing and red herrings is crucial in maintaining suspense.  By subtly hinting at future events or misleading the audience, creators can keep viewers on the edge of their seats, constantly questioning their assumptions and anticipating the next development.\n",
              "\n",
              "Finally, the visual and auditory aspects of anime are integral to creating a truly suspenseful atmosphere.  The use of shadows, lighting, and color palettes can significantly contribute to the overall mood, while sound design, including music and sound effects, can amplify the tension and heighten the emotional impact of key scenes.  The combination of these elements creates a synergistic effect, enhancing the overall viewing experience and solidifying the anime's place within the genre.\n",
              "\n",
              "\n",
              "## Comparison Table: *Monster* vs. *Psycho-Pass*\n",
              "\n",
              "| Feature          | Option A: *Monster*                               | Option B: *Psycho-Pass*                             |\n",
              "|-----------------|----------------------------------------------------|-----------------------------------------------------|\n",
              "| **Genre Focus**   | Psychological Thriller, Mystery                  | Cyberpunk Thriller, Sci-Fi, Psychological           |\n",
              "| **Protagonist**   | Dr. Kenzo Tenma, a neurosurgeon                  | Inspectors of the Sibyl System                       |\n",
              "| **Antagonist**    | Johan Liebert, a manipulative serial killer       | Criminals, the Sibyl System itself (arguably)       |\n",
              "| **Setting**       | Primarily Europe, spanning several years          | Futuristic dystopian Japan                           |\n",
              "| **Pace**          | Slow-burn, methodical investigation              | Faster-paced, episodic with overarching narrative     |\n",
              "| **Visual Style**  | Realistic, grounded                               | Stylized, futuristic                                  |\n",
              "| **Themes**        | Morality, consequences of actions, nature vs. nurture | Justice, ethics, societal control, technological advancement |\n",
              "\n",
              "\n",
              "## Pros & Cons\n",
              "\n",
              "**Monster:**\n",
              "\n",
              "**Pros:**\n",
              "* Exceptional character development\n",
              "* Complex and morally ambiguous narrative\n",
              "* Masterful suspense building\n",
              "* Thought-provoking themes\n",
              "\n",
              "**Cons:**\n",
              "* Slow pace may not appeal to all viewers\n",
              "* Can be emotionally draining\n",
              "\n",
              "\n",
              "**Psycho-Pass:**\n",
              "\n",
              "**Pros:**\n",
              "* Fast-paced and engaging plot\n",
              "* Futuristic setting and unique premise\n",
              "* Explores complex ethical dilemmas\n",
              "* Visually stunning\n",
              "\n",
              "**Cons:**\n",
              "* Some plot points can feel convoluted\n",
              "* The Sibyl System's nature is somewhat ambiguous\n",
              "\n",
              "\n",
              "## Citations / References\n",
              "\n",
              "While specific episode titles and streaming service links are dynamic, general references can be made:\n",
              "\n",
              "*  MyAnimeList database entries for *Monster* and *Psycho-Pass*.\n",
              "*  Various anime review websites and forums (e.g., Reddit's r/anime).\n",
              "*  Articles and discussions on anime blogs and news sites.\n",
              "\n",
              "\n",
              "**Note:**  Specific URLs are omitted as they are subject to change.  Searching for the titles \"*Monster*\" and \"*Psycho-Pass*\" on relevant platforms will provide access to the cited resources."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "topic = \"Best anime with suspense and thiller genre\"\n",
        "\n",
        "report = chain.run(topic=topic, today=today)\n",
        "\n",
        "display(Markdown(report))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLAaVujMe5Za"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
